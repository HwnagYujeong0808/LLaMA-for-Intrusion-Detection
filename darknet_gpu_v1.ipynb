{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "17dae456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 1/17, Loss: 13328.412109375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 2/17, Loss: 3447.844482421875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 3/17, Loss: 12018.7255859375, Accuracy: 0.12000000000000002\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 4/17, Loss: 4587.74169921875, Accuracy: 0.02857142857142857\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 5/17, Loss: 3511.83740234375, Accuracy: 0.03333333333333334\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 6/17, Loss: 11470.8984375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 7/17, Loss: 4445.24169921875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 8/17, Loss: 12191.1875, Accuracy: 0.01818181818181818\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 9/17, Loss: 6497.1630859375, Accuracy: 0.06666666666666668\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 10/17, Loss: 2356.62060546875, Accuracy: 0.1\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 11/17, Loss: 5034.734375, Accuracy: 0.05\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 12/17, Loss: 6301.2314453125, Accuracy: 0.13333333333333333\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 13/17, Loss: 3556.80322265625, Accuracy: 0.06666666666666667\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 14/17, Loss: 11302.9892578125, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 15/17, Loss: 2515.65234375, Accuracy: 0.1\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 16/17, Loss: 9317.287109375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 17/17, Loss: 2760.697021484375, Accuracy: 0.11428571428571428\n",
      "Epoch: 1\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 1/17, Loss: 5978.7451171875, Accuracy: 0.044444444444444446\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 2/17, Loss: 6495.884765625, Accuracy: 0.07272727272727272\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 3/17, Loss: 9216.9677734375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 4/17, Loss: 4719.2236328125, Accuracy: 0.1\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 5/17, Loss: 5674.05224609375, Accuracy: 0.019999999999999997\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 6/17, Loss: 1755.2425537109375, Accuracy: 0.2\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 7/17, Loss: 6670.2978515625, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 8/17, Loss: 7582.21240234375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 9/17, Loss: 16052.5654296875, Accuracy: 0.06666666666666668\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 10/17, Loss: 6040.7890625, Accuracy: 0.04\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 11/17, Loss: 10067.3603515625, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 12/17, Loss: 3400.130126953125, Accuracy: 0.06666666666666667\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 13/17, Loss: 3335.044189453125, Accuracy: 0.02222222222222222\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 14/17, Loss: 6602.703125, Accuracy: 0.06666666666666667\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 15/17, Loss: 8774.337890625, Accuracy: 0.01818181818181818\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 16/17, Loss: 3851.28076171875, Accuracy: 0.12222222222222223\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 17/17, Loss: 8634.513671875, Accuracy: 0.01818181818181818\n",
      "Epoch: 2\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 1/17, Loss: 3106.69482421875, Accuracy: 0.10909090909090909\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 2/17, Loss: 7361.6328125, Accuracy: 0.06666666666666668\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 3/17, Loss: 8390.69140625, Accuracy: 0.02222222222222222\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 4/17, Loss: 5869.8544921875, Accuracy: 0.075\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 5/17, Loss: 6366.7119140625, Accuracy: 0.04\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 6/17, Loss: 6070.21826171875, Accuracy: 0.06666666666666667\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 7/17, Loss: 4675.6103515625, Accuracy: 0.2\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 8/17, Loss: 12416.18359375, Accuracy: 0.04\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 9/17, Loss: 4012.11279296875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 10/17, Loss: 9056.6083984375, Accuracy: 0.06666666666666668\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 11/17, Loss: 5700.2060546875, Accuracy: 0.2\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 12/17, Loss: 6615.5166015625, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 13/17, Loss: 12502.908203125, Accuracy: 0.01818181818181818\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 14/17, Loss: 2930.0048828125, Accuracy: 0.10909090909090909\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 15/17, Loss: 5275.5712890625, Accuracy: 0.08333333333333334\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 16/17, Loss: 3742.882080078125, Accuracy: 0.025\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 17/17, Loss: 6176.96923828125, Accuracy: 0.01818181818181818\n",
      "Epoch: 3\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 1/17, Loss: 8045.3876953125, Accuracy: 0.01818181818181818\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 2/17, Loss: 5325.03564453125, Accuracy: 0.12444444444444444\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 3/17, Loss: 3605.498046875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 4/17, Loss: 5994.33203125, Accuracy: 0.15\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 5/17, Loss: 4873.30078125, Accuracy: 0.05\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 6/17, Loss: 7083.0654296875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 7/17, Loss: 3891.735595703125, Accuracy: 0.05\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 8/17, Loss: 3857.051513671875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 9/17, Loss: 5967.56494140625, Accuracy: 0.05714285714285715\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 10/17, Loss: 4863.154296875, Accuracy: 0.02222222222222222\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 11/17, Loss: 3225.5341796875, Accuracy: 0.08888888888888889\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 12/17, Loss: 6511.4716796875, Accuracy: 0.04\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 13/17, Loss: 3910.844482421875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 14/17, Loss: 2898.91357421875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 15/17, Loss: 4675.06103515625, Accuracy: 0.08\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 16/17, Loss: 4820.6689453125, Accuracy: 0.044444444444444446\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 17/17, Loss: 9044.5986328125, Accuracy: 0.0\n",
      "Epoch: 4\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 1/17, Loss: 5186.38134765625, Accuracy: 0.06666666666666667\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 2/17, Loss: 5657.6767578125, Accuracy: 0.08\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 3/17, Loss: 4353.52197265625, Accuracy: 0.1\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 4/17, Loss: 7336.1240234375, Accuracy: 0.15\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 5/17, Loss: 7935.65478515625, Accuracy: 0.06666666666666668\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 6/17, Loss: 12175.34375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 7/17, Loss: 7196.0810546875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 8/17, Loss: 10563.6435546875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 9/17, Loss: 4006.51513671875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 10/17, Loss: 11656.0029296875, Accuracy: 0.019999999999999997\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 11/17, Loss: 4768.60546875, Accuracy: 0.08888888888888889\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 12/17, Loss: 7043.6123046875, Accuracy: 0.06666666666666668\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 13/17, Loss: 4205.45458984375, Accuracy: 0.06666666666666667\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 14/17, Loss: 15711.220703125, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 15/17, Loss: 6618.28271484375, Accuracy: 0.01818181818181818\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 16/17, Loss: 5654.28125, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 17/17, Loss: 5925.98388671875, Accuracy: 0.0\n",
      "Epoch: 5\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 1/17, Loss: 7000.8046875, Accuracy: 0.019999999999999997\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 2/17, Loss: 4922.5947265625, Accuracy: 0.08888888888888889\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 3/17, Loss: 4615.81640625, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 4/17, Loss: 6957.7900390625, Accuracy: 0.08\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 5/17, Loss: 5537.48193359375, Accuracy: 0.019999999999999997\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 6/17, Loss: 4605.24755859375, Accuracy: 0.04\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 7/17, Loss: 6562.48974609375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 8/17, Loss: 6005.26171875, Accuracy: 0.02222222222222222\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 9/17, Loss: 4915.4033203125, Accuracy: 0.14761904761904762\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 10/17, Loss: 2665.183349609375, Accuracy: 0.13846153846153847\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 11/17, Loss: 3873.178466796875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 12/17, Loss: 15802.4296875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 13/17, Loss: 11853.0498046875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 14/17, Loss: 5846.58984375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 15/17, Loss: 4911.08837890625, Accuracy: 0.05714285714285715\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 16/17, Loss: 5535.501953125, Accuracy: 0.15\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 17/17, Loss: 2907.44091796875, Accuracy: 0.13214285714285717\n",
      "Epoch: 6\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 1/17, Loss: 6523.40869140625, Accuracy: 0.02222222222222222\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 2/17, Loss: 4661.9091796875, Accuracy: 0.06666666666666667\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 3/17, Loss: 2751.586669921875, Accuracy: 0.1\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 4/17, Loss: 3734.616455078125, Accuracy: 0.1\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 5/17, Loss: 6059.02197265625, Accuracy: 0.01818181818181818\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 6/17, Loss: 6530.0458984375, Accuracy: 0.01818181818181818\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 7/17, Loss: 2702.55224609375, Accuracy: 0.16666666666666666\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 8/17, Loss: 4673.6357421875, Accuracy: 0.03333333333333334\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 9/17, Loss: 6814.01708984375, Accuracy: 0.13333333333333333\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 10/17, Loss: 5020.82177734375, Accuracy: 0.17142857142857143\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 11/17, Loss: 5005.12353515625, Accuracy: 0.03636363636363636\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 12/17, Loss: 3876.286376953125, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 13/17, Loss: 5688.6025390625, Accuracy: 0.06666666666666667\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 14/17, Loss: 5445.4951171875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 15/17, Loss: 5042.20068359375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 16/17, Loss: 4092.884033203125, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 17/17, Loss: 3179.0439453125, Accuracy: 0.02222222222222222\n",
      "Epoch: 7\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 1/17, Loss: 5642.9951171875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 2/17, Loss: 12171.724609375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 3/17, Loss: 11069.884765625, Accuracy: 0.02222222222222222\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 4/17, Loss: 8705.498046875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 5/17, Loss: 3385.635986328125, Accuracy: 0.1\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 6/17, Loss: 7346.0380859375, Accuracy: 0.22000000000000003\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 7/17, Loss: 3892.03857421875, Accuracy: 0.15555555555555553\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 8/17, Loss: 5621.4052734375, Accuracy: 0.10500000000000001\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 9/17, Loss: 5474.7490234375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 10/17, Loss: 4718.17724609375, Accuracy: 0.13999999999999999\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 11/17, Loss: 8287.966796875, Accuracy: 0.025\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 12/17, Loss: 8157.62646484375, Accuracy: 0.13846153846153847\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 13/17, Loss: 3656.26953125, Accuracy: 0.25\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 14/17, Loss: 7654.4921875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 15/17, Loss: 9906.73046875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 16/17, Loss: 2287.07177734375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 17/17, Loss: 4737.06591796875, Accuracy: 0.25\n",
      "Epoch: 8\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 1/17, Loss: 9173.9228515625, Accuracy: 0.08\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 2/17, Loss: 4843.5693359375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 3/17, Loss: 5553.80322265625, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 4/17, Loss: 4506.720703125, Accuracy: 0.13846153846153847\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 5/17, Loss: 12104.4111328125, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 6/17, Loss: 3018.340087890625, Accuracy: 0.125\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 7/17, Loss: 5824.8115234375, Accuracy: 0.06666666666666668\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 8/17, Loss: 8708.720703125, Accuracy: 0.01818181818181818\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 9/17, Loss: 5110.419921875, Accuracy: 0.01818181818181818\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 10/17, Loss: 10737.5126953125, Accuracy: 0.05\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 11/17, Loss: 5166.12890625, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 12/17, Loss: 3963.79443359375, Accuracy: 0.06000000000000001\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 13/17, Loss: 7567.73046875, Accuracy: 0.01818181818181818\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 14/17, Loss: 3410.871826171875, Accuracy: 0.1\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 15/17, Loss: 6091.7001953125, Accuracy: 0.01818181818181818\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 16/17, Loss: 2776.255859375, Accuracy: 0.08\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 17/17, Loss: 7500.04833984375, Accuracy: 0.01818181818181818\n",
      "Epoch: 9\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 1/17, Loss: 5014.041015625, Accuracy: 0.05\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 2/17, Loss: 4505.5947265625, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 3/17, Loss: 5610.79248046875, Accuracy: 0.14222222222222225\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 4/17, Loss: 1992.2406005859375, Accuracy: 0.21142857142857144\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 5/17, Loss: 5596.87548828125, Accuracy: 0.1\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 6/17, Loss: 8215.5439453125, Accuracy: 0.08\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 7/17, Loss: 6865.97412109375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 8/17, Loss: 8133.41552734375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 9/17, Loss: 4987.4033203125, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 10/17, Loss: 1789.7125244140625, Accuracy: 0.08888888888888889\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 11/17, Loss: 4865.24658203125, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 12/17, Loss: 5057.7451171875, Accuracy: 0.16363636363636364\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 13/17, Loss: 9082.9951171875, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 14/17, Loss: 7634.85302734375, Accuracy: 0.0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 15/17, Loss: 4648.92822265625, Accuracy: 0.14666666666666667\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 16/17, Loss: 4775.8212890625, Accuracy: 0.06666666666666667\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "Batch 17/17, Loss: 7712.9697265625, Accuracy: 0.13846153846153847\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "import argparse \n",
    "import numpy as np \n",
    "import time \n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pickle\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "\n",
    "class LLMGraphTransformer(nn.Module):\n",
    "    def __init__(self, model_name=\"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\", in_feats=9, hidden_size=16, out_feats=9, num_heads=4, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        # Load the tokenizer and model for TinyLlama\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name).to(self.device)\n",
    "\n",
    "        # Ensure padding token is set for TinyLlama\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "        # Graph Transformer Layers for additional processing\n",
    "        self.graph_transformer1 = GraphTransformerLayer(in_feats, hidden_size, num_heads=num_heads)\n",
    "        self.graph_transformer2 = GraphTransformerLayer(hidden_size * num_heads, out_feats, num_heads=1)\n",
    "\n",
    "        # Projection Layer to match text and graph embedding dimensions\n",
    "        self.text_embedding_dim = 64  # Match this to text embeddings size (64)\n",
    "        self.graph_embedding_dim = 9  # Match this to graph embeddings size (9)\n",
    "        self.projection = nn.Linear(self.text_embedding_dim + self.graph_embedding_dim, out_feats).to(self.device)\n",
    "        \n",
    "        # Final classification layer\n",
    "        self.classifier = nn.Linear(out_feats, out_feats).to(self.device)\n",
    "\n",
    "    def forward(self, input_texts, graph_data):\n",
    "        batch_graphs, node_features, edge_features = graph_data\n",
    "\n",
    "        # Move the graph to the correct device\n",
    "        batch_graphs = batch_graphs\n",
    "\n",
    "        # Process input text with TinyLlama to generate embeddings\n",
    "        inputs = self.tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(self.device)  # Ensure inputs are on the same device\n",
    "        outputs = self.model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_new_tokens=10)\n",
    "\n",
    "        # Convert generated tokens back to embeddings\n",
    "        generated_texts = [self.tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "        text_embeddings = self.tokenizer(generated_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)['input_ids'].to(self.device)  # Move to the correct device\n",
    "\n",
    "        # Project text_embeddings to the correct size\n",
    "        text_embeddings = text_embeddings.float()  # Ensure text embeddings are of type float\n",
    "        text_embedding_dim = text_embeddings.size(1)\n",
    "        linear_text_projection = nn.Linear(text_embedding_dim, self.text_embedding_dim).to(self.device)\n",
    "        text_embeddings = linear_text_projection(text_embeddings)\n",
    "\n",
    "        # Process graph data using Graph Transformer\n",
    "        x = self.graph_transformer1(batch_graphs, node_features)  # Outputs [1000, 64]\n",
    "        linear_layer = nn.Linear(16, 64) # 16 dimensions to 64 dimensions\n",
    "        x = linear_layer(x)\n",
    "        x = self.graph_transformer2(batch_graphs, x)  # Input is now [1000, 64]\n",
    "        x = x.to(self.device)\n",
    "\n",
    "        # Adjust the batch size of text embeddings to match graph embeddings\n",
    "        text_embeddings = text_embeddings.repeat(x.size(0) // text_embeddings.size(0), 1)\n",
    "\n",
    "        # Combine text embeddings and graph embeddings\n",
    "        combined_embeddings = torch.cat([text_embeddings, x], dim=1).to(self.device)  # Concatenate along dimension 1\n",
    "\n",
    "        # Check combined embeddings size\n",
    "#         print(f\"combined_embeddings shape: {combined_embeddings.shape}\")  # Should be [1000, 73]\n",
    "\n",
    "        # Apply projection layer to match output dimension\n",
    "        combined_embeddings = self.projection(combined_embeddings)\n",
    "\n",
    "        # Final classification layer\n",
    "        logits = self.classifier(combined_embeddings)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def generate_text(self, graph_data, labels, max_new_tokens=50):\n",
    "        # Convert the graph adjacency list to text directly within this method\n",
    "        batch_text = []\n",
    "        for node, neighbors in enumerate(graph_data):\n",
    "            if isinstance(neighbors, (list, set, np.ndarray)):\n",
    "                for neighbor in neighbors:\n",
    "                    question = f\"What is the relationship between Node {node} and Node {neighbor}? Choices: {', '.join(labels)}.\"\n",
    "                    batch_text.append(question)\n",
    "            else:\n",
    "                question = f\"What is the relationship between Node {node} and Node {neighbors}? Choices: {', '.join(labels)}.\"\n",
    "                batch_text.append(question)\n",
    "\n",
    "        # Tokenize and generate predictions\n",
    "        inputs = self.tokenizer(batch_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(self.device)  # Move to the correct device\n",
    "#         print(\"inputs generated\")\n",
    "        outputs = self.model.generate(\n",
    "            inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            do_sample=True\n",
    "        )\n",
    "#         print(\"outputs generated\")\n",
    "        generated_text = [self.tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "        return generated_text\n",
    "\n",
    "\n",
    "\n",
    "class GraphTransformerLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_heads=4, dropout=0.1):\n",
    "        super(GraphTransformerLayer, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Each head should process a fraction of the input features\n",
    "        assert out_dim % num_heads == 0, \"Output dimension must be divisible by the number of heads\"\n",
    "        self.head_dim = out_dim // num_heads  # Calculate dimension per head\n",
    "\n",
    "        # Multi-head graph attention mechanism\n",
    "        self.attn_fc = nn.ModuleList([nn.Linear(in_dim, self.head_dim, bias=False) for _ in range(num_heads)])\n",
    "\n",
    "        # Feedforward layer\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(out_dim, out_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_dim, out_dim)\n",
    "        )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(out_dim)\n",
    "        self.norm2 = nn.LayerNorm(out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            # Initialize attention values for edges\n",
    "            g.edata['attn'] = torch.ones(g.number_of_edges(), self.num_heads).to(h.device)  # Initialize attention scores\n",
    "\n",
    "            # Multi-head attention\n",
    "            head_outputs = []\n",
    "            for i in range(self.num_heads):\n",
    "                Wh = self.attn_fc[i](h)  # Ensure Wh is computed per-head\n",
    "                g.ndata['Wh'] = Wh\n",
    "                # Ensure dimensions match between Wh (nodes) and attn (edges)\n",
    "                g.update_all(dgl.function.u_mul_e('Wh', 'attn', 'm'), dgl.function.sum('m', 'h'))\n",
    "                head_outputs.append(g.ndata['h'])\n",
    "\n",
    "            # Concatenate the heads\n",
    "            h = torch.cat(head_outputs, dim=1)\n",
    "\n",
    "            # Add & Norm\n",
    "            h = self.norm1(h)\n",
    "            h = F.relu(h)\n",
    "\n",
    "            # Feedforward\n",
    "            h = self.ff(h)\n",
    "\n",
    "            # Add & Norm\n",
    "            h = self.norm2(h)\n",
    "            h = self.dropout(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "# Prepare graph data for graph transformer layers\n",
    "def prepare_graph_data(graphs, num_node_features=9, device=\"cpu\"):\n",
    "    for graph in graphs:\n",
    "        num_nodes = graph.number_of_nodes()\n",
    "        if 'feat' not in graph.ndata:\n",
    "            graph.ndata['feat'] = torch.randn(num_nodes, num_node_features).to(device)  # Move to correct device\n",
    "\n",
    "        num_edges = graph.number_of_edges()\n",
    "        if 'feat' not in graph.edata:\n",
    "            graph.edata['feat'] = torch.randn(num_edges, num_node_features).to(device)  # Move to correct device\n",
    "\n",
    "    batch_graphs = dgl.batch(graphs)\n",
    "    node_features = batch_graphs.ndata['feat']\n",
    "    edge_features = batch_graphs.edata['feat']\n",
    "    return batch_graphs, node_features, edge_features\n",
    "\n",
    "\n",
    "# Data balancing function\n",
    "def balance_data(data, labels, n_samples_per_label):\n",
    "    label_groups = {}\n",
    "    for label in np.unique(labels):\n",
    "        label_indices = np.where(labels == label)[0]\n",
    "        sampled_indices = np.random.choice(label_indices, size=n_samples_per_label, replace=(len(label_indices) < n_samples_per_label))\n",
    "        label_groups[label] = sampled_indices\n",
    "\n",
    "    balanced_indices = np.concatenate(list(label_groups.values()))\n",
    "    balanced_data = data[balanced_indices]\n",
    "    balanced_labels = labels[balanced_indices]\n",
    "\n",
    "    return balanced_data, balanced_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def fit(args):\n",
    "    data = args[\"dataset\"]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "\n",
    "    # Load the data manually (edge_feat, label, adj, adj_lists, config)\n",
    "    path = \"datasets/\" + data + \"/\"\n",
    "    edge_feat = np.load(path + \"edge_feat_scaled.npy\", allow_pickle=True)\n",
    "    label = np.load(path + \"label_mul.npy\", allow_pickle=True)\n",
    "    adj = np.load(path + \"adj_random.npy\", allow_pickle=True)\n",
    "    with open(path + 'adj_random_list.dict', 'rb') as file:\n",
    "        adj_lists = pickle.load(file)\n",
    "\n",
    "    # Initialize LLMGraphTransformer using TinyLlama\n",
    "    model = LLMGraphTransformer(device=device)\n",
    "    labels = ['Normal', 'Audio-Streaming', 'Browsing', 'Chat', 'File-Transfer', 'Email', 'P2P', 'Video-Streaming', 'VOIP']\n",
    "\n",
    "    # Optimizer and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Balance the dataset\n",
    "    balanced_data, balanced_labels = balance_data(np.arange(len(edge_feat)), label, n_samples_per_label=30)\n",
    "\n",
    "    # Split the data into train, validation, and test sets\n",
    "    train_val, test, train_val_labels, test_labels = train_test_split(balanced_data, balanced_labels, test_size=0.2, stratify=balanced_labels)\n",
    "    train, val, train_labels, val_labels = train_test_split(train_val, train_val_labels, test_size=0.2, stratify=train_val_labels)\n",
    "\n",
    "    times = []\n",
    "    trainscores = []\n",
    "    valscores = []\n",
    "\n",
    "    for epoch in range(10):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        random.shuffle(train)\n",
    "        \n",
    "\n",
    "        for batch in range(int(len(train) / 10)):  # Batch size is 10\n",
    "            batch_edges = train[10 * batch:10 * (batch + 1)]\n",
    "             \n",
    "            # Print the number of batches\n",
    "            print(f\"Training data size: {len(train)}\")\n",
    "            print(f\"Number of batches: {len(train) // 10}\")\n",
    "\n",
    "            # Prepare graph data (initialize with random node features)\n",
    "            graph_data = prepare_graph_data([dgl.rand_graph(100, 200) for _ in batch_edges], num_node_features=9) \n",
    "\n",
    "            # Convert batch_edges to text\n",
    "            batch_text = model.generate_text(batch_edges, labels, max_new_tokens=10)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            logits = model(batch_text, graph_data)\n",
    "            \n",
    "            # Ensure batch_labels are converted to LongTensor\n",
    "            batch_labels = torch.tensor(train_labels[10 * batch:10 * (batch + 1)], device=device, dtype=torch.long)  # Convert to LongTensor\n",
    "\n",
    "            # Print shapes to debug\n",
    "#             print(f\"logits shape: {logits.shape}\")   # Check the logits shape\n",
    "#             print(f\"batch_labels shape: {batch_labels.shape}\")  # Check the labels shape\n",
    "\n",
    "            # Adjust logits size to match batch_labels if necessary\n",
    "            if logits.size(0) > batch_labels.size(0):\n",
    "                logits = logits[:batch_labels.size(0)]\n",
    "            print(logits)\n",
    "            loss = loss_fn(logits, batch_labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            acc_train = f1_score(batch_labels.cpu().numpy(), predicted_labels.cpu().numpy(), average=\"weighted\")\n",
    "\n",
    "            print(f'Batch {batch + 1}/{len(train) // 10}, Loss: {loss.item()}, Accuracy: {acc_train}')\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "\n",
    "# Prediction function\n",
    "def predict(model, data_idx):\n",
    "    model.eval()\n",
    "    predict_output = []\n",
    "    labels = ['Normal', 'Audio-Streaming', 'Browsing', 'Chat', 'File-Transfer', 'Email', 'P2P', 'Video-Streaming', 'VOIP']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in range(int(len(data_idx) / 10)):\n",
    "            batch_edges = data_idx[10 * batch:10 * (batch + 1)]\n",
    "            graph_data = prepare_graph_data([dgl.rand_graph(100, 200) for _ in batch_edges], num_node_features=9, device=device)\n",
    "\n",
    "            # Convert batch_edges to text\n",
    "            batch_text = model.generate_text(batch_edges, labels, max_new_tokens=10)\n",
    "\n",
    "            # Forward pass\n",
    "            logits = model(batch_text, graph_data)\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            predict_output.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "    return predict_output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fit({\"dataset\": \"Darknet\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0ca9fff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training data size: 172\n",
      "Number of batches: 17\n",
      "inputs generated\n",
      "outputs generated\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1000x84 and 576x9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 94\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict_output\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDarknet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[69], line 53\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     51\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m batch_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(train_labels[\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m batch:\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m (batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[68], line 68\u001b[0m, in \u001b[0;36mLLMGraphTransformer.forward\u001b[0;34m(self, input_texts, graph_data)\u001b[0m\n\u001b[1;32m     65\u001b[0m combined_embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([text_embeddings, x], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# Concatenate along dimension 1\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Apply projection layer to match output dimension\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m combined_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprojection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Final classification layer\u001b[39;00m\n\u001b[1;32m     71\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(combined_embeddings)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1000x84 and 576x9)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "935fdca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "DGLError",
     "evalue": "[17:39:04] /opt/dgl/src/runtime/c_runtime_api.cc:88: Check failed: allow_missing: Device API gpu is not enabled. Please install the cuda version of dgl.\nStack trace:\n  [bt] (0) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f1c4806203f]\n  [bt] (1) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::runtime::DeviceAPIManager::GetAPI(std::string, bool)+0x374) [0x7f1c487565d4]\n  [bt] (2) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::runtime::DeviceAPI::Get(DLContext, bool)+0x1f4) [0x7f1c487502b4]\n  [bt] (3) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DLDataType, DLContext)+0x334) [0x7f1c48771e64]\n  [bt] (4) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyTo(DLContext const&) const+0xc0) [0x7f1c487a8cd0]\n  [bt] (5) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::aten::COOMatrix::CopyTo(DLContext const&) const+0x7d) [0x7f1c48898c4d]\n  [bt] (6) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0x292) [0x7f1c488893d2]\n  [bt] (7) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0xf5) [0x7f1c487b9ef5]\n  [bt] (8) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(+0x97d3bb) [0x7f1c487c73bb]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create a DGL graph and move it to the GPU\u001b[39;00m\n\u001b[1;32m      8\u001b[0m g \u001b[38;5;241m=\u001b[39m dgl\u001b[38;5;241m.\u001b[39mrand_graph(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Check if the graph is on the GPU\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(g\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/heterograph.py:5192\u001b[0m, in \u001b[0;36mDGLHeteroGraph.to\u001b[0;34m(self, device, **kwargs)\u001b[0m\n\u001b[1;32m   5189\u001b[0m ret \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   5191\u001b[0m \u001b[38;5;66;03m# 1. Copy graph structure\u001b[39;00m\n\u001b[0;32m-> 5192\u001b[0m ret\u001b[38;5;241m.\u001b[39m_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dgl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5194\u001b[0m \u001b[38;5;66;03m# 2. Copy features\u001b[39;00m\n\u001b[1;32m   5195\u001b[0m \u001b[38;5;66;03m# TODO(minjie): handle initializer\u001b[39;00m\n\u001b[1;32m   5196\u001b[0m new_nframes \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/dgl/heterograph_index.py:234\u001b[0m, in \u001b[0;36mHeteroGraphIndex.copy_to\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy_to\u001b[39m(\u001b[38;5;28mself\u001b[39m, ctx):\n\u001b[1;32m    220\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Copy this immutable graph index to the given device context.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    NOTE: this method only works for immutable graph index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m        The graph index on the given device context.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_CAPI_DGLHeteroCopyTo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mdgl/_ffi/_cython/./function.pxi:287\u001b[0m, in \u001b[0;36mdgl._ffi._cy3.core.FunctionBase.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mdgl/_ffi/_cython/./function.pxi:222\u001b[0m, in \u001b[0;36mdgl._ffi._cy3.core.FuncCall\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mdgl/_ffi/_cython/./function.pxi:211\u001b[0m, in \u001b[0;36mdgl._ffi._cy3.core.FuncCall3\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mdgl/_ffi/_cython/./base.pxi:155\u001b[0m, in \u001b[0;36mdgl._ffi._cy3.core.CALL\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDGLError\u001b[0m: [17:39:04] /opt/dgl/src/runtime/c_runtime_api.cc:88: Check failed: allow_missing: Device API gpu is not enabled. Please install the cuda version of dgl.\nStack trace:\n  [bt] (0) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f1c4806203f]\n  [bt] (1) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::runtime::DeviceAPIManager::GetAPI(std::string, bool)+0x374) [0x7f1c487565d4]\n  [bt] (2) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::runtime::DeviceAPI::Get(DLContext, bool)+0x1f4) [0x7f1c487502b4]\n  [bt] (3) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DLDataType, DLContext)+0x334) [0x7f1c48771e64]\n  [bt] (4) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyTo(DLContext const&) const+0xc0) [0x7f1c487a8cd0]\n  [bt] (5) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::aten::COOMatrix::CopyTo(DLContext const&) const+0x7d) [0x7f1c48898c4d]\n  [bt] (6) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0x292) [0x7f1c488893d2]\n  [bt] (7) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DLContext const&)+0xf5) [0x7f1c487b9ef5]\n  [bt] (8) /usr/local/lib/python3.8/dist-packages/dgl/libdgl.so(+0x97d3bb) [0x7f1c487c73bb]\n\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "\n",
    "# Check if PyTorch can use the GPU\n",
    "print(torch.cuda.is_available())  # Should print: True\n",
    "\n",
    "# Create a DGL graph and move it to the GPU\n",
    "g = dgl.rand_graph(100, 200)\n",
    "g = g.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Check if the graph is on the GPU\n",
    "print(g.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "285405a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "174a40dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: dgl 0.6.1\n",
      "Uninstalling dgl-0.6.1:\n",
      "  Successfully uninstalled dgl-0.6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y dgl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba0c04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dgl-cu102==0.6.1\n",
      "  Downloading dgl_cu102-0.6.1-cp38-cp38-manylinux1_x86_64.whl (36.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from dgl-cu102==0.6.1) (1.22.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from dgl-cu102==0.6.1) (2.32.3)\n",
      "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.8/dist-packages (from dgl-cu102==0.6.1) (2.8.8)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from dgl-cu102==0.6.1) (1.6.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl-cu102==0.6.1) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl-cu102==0.6.1) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl-cu102==0.6.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->dgl-cu102==0.6.1) (1.26.14)\n",
      "Installing collected packages: dgl-cu102\n",
      "Successfully installed dgl-cu102-0.6.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install dgl-cu102==0.6.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270487f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
